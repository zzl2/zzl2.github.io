---
title: Comprehensive data exploration with Python
date: 2017-12-04 20:39:03
tags: About Data
---

#                      关于数据的处理#

 理解问题


​	审查每一个变量，并且对他们的意义和对于这个问题的重要性做一个大致的分析。

 单变量的研究

​	应该将主要的精力放在因变量上，并且深入的理解这个变量。

多变量研究

​	理解因变量和自变量之间的关系。

基本的数据清洗

​	对于数据的缺失，异常值和分类变量（文本变量）的处理。

测试

​	检查我的数据是否符合机器学习模型的要求，然后测试

# 理解问题#

​	为了更好的了解数据，我们需要观察每一个变量并去理解他们的意义。从逻辑上考虑他们的关系。为了更好的达到这个效果可以采用建立表格的方式。例如：变量、变量类型、类别、预测、结论、评论。

# 因变量的分析#

​	可以用seaborn 来画图看它的 正态分布、有无明显的正偏态、数据显示尖锐。

这一部分的重点就是以一个非常片面的方式测试SalePrice。我们将会把重点放在：

{% asset_img  56.jpg  % }

矩形图: 峰值和偏度

<!--more-->

正态概率图:数据分布将会紧紧的贴合代表正态分布的那条线

好的，SalePrice并不是正态的，它显示出尖峰性，正偏态并且并不贴合那条正态分布的直线。但是没有信息丢失了。一个简单的数据转换就可以解决这个问题。这是个你可以在数据书里学到的很有用的方法：在正偏态分布的情况下，log 转换表现的很好.

# 多变量研究#

​	首先是和数值型或者类别变量的关系，通过散点图看趋势。通过相关矩阵来看。其实就是通过画图来分析他们之间的关系。

#  数据的清洗#

首先应该考虑的就是缺失值，在我们思考缺失数据时有两个重要的问题：

- 缺失数据有多普遍？
- 缺失数据是否存在某种规律或者就是随机的？

我们将会考虑扔掉缺失率超过15%的数据。再观察这些缺失值之间的关系，比如说这些缺失值缺少的是同一行的数据，或者其他。

​	其次我们应该烤炉的就是异常值。因为异常值会显著的影响我们的模型，并且能够给我们提供很有价值的信息，一些关于特殊行为的视角。首先利用单一变量分析，先标准化，然后再把它观察。其次就是利用多变量来分析，利用散点图来分析。

#哑变量#

​	df_train=pd.get_dummies(df_train)

[参考代码](https://github.com/zzl2/house_price/blob/master/downcode.py)
